{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.initializers import Ones\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIM_EMBEDDING = 100\n",
    "LEN_VOC = 1000\n",
    "LSTM_UNIT1 = 32\n",
    "LSTM_UNIT2 = 16\n",
    "LEN_S1 = 50\n",
    "LEN_S2 = 40\n",
    "POOL_SIZE = 2\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试自己写的ESIM是否正确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自己编写ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sen1 (InputLayer)               (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sen2 (InputLayer)               (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_encoder (Embedding)        multiple             100000      sen1[0][0]                       \n",
      "                                                                 sen2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) multiple             34048       word_encoder[0][0]               \n",
      "                                                                 word_encoder[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 50, 40)       0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 40, 50)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 50, 40)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 64, 40)       0           bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 40, 50)       0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 64, 50)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 50, 64)       0           activation_1[0][0]               \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 40, 64)       0           activation_2[0][0]               \n",
      "                                                                 permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           multiple             0           bidirectional_1[0][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "                                                                 dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           multiple             0           bidirectional_1[0][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "                                                                 dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "context_concatenate (Concatenat multiple             0           bidirectional_1[0][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 multiply_1[0][0]                 \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "                                                                 dot_3[0][0]                      \n",
      "                                                                 subtract_1[1][0]                 \n",
      "                                                                 multiply_1[1][0]                 \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) multiple             34944       context_concatenate[0][0]        \n",
      "                                                                 context_concatenate[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 32)           0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 32)           0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         context_concatenate[2][0]        \n",
      "==================================================================================================\n",
      "Total params: 169,121\n",
      "Trainable params: 169,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "WordEncoder = Embedding(input_dim=LEN_VOC, output_dim=DIM_EMBEDDING, name='word_encoder',\n",
    "                        embeddings_initializer=Ones())\n",
    "ContextEncoder = Bidirectional(LSTM(LSTM_UNIT1, return_sequences=True, name='context_encoder',\n",
    "                     recurrent_initializer=Ones(), kernel_initializer=Ones(), bias_initializer=Ones()))\n",
    "ContextEncoder2 = Bidirectional(LSTM(LSTM_UNIT2, return_sequences=True, name='context_encoder2',\n",
    "                     recurrent_initializer=Ones(), kernel_initializer=Ones(), bias_initializer=Ones()))\n",
    "SharpenContext = Subtract()\n",
    "FilterContext = Multiply()\n",
    "ContextConcatenate = Concatenate(axis=-1, name='context_concatenate')\n",
    "RelationConcatenate = Concatenate(axis=-1, name='relation_concatenate')\n",
    "\n",
    "\n",
    "print('build model...')\n",
    "# input encoding\n",
    "s1 = Input(batch_shape=[None, LEN_S1], name='sen1')\n",
    "s2 = Input(batch_shape=[None, LEN_S2], name='sen2')\n",
    "s1_embeded = WordEncoder(s1)\n",
    "s2_embeded = WordEncoder(s2)\n",
    "s1_encoded = ContextEncoder(s1_embeded)\n",
    "s2_encoded = ContextEncoder(s2_embeded)\n",
    "# local inference\n",
    "dot = Dot(axes=-1)([s1_encoded, s2_encoded])\n",
    "s1_attention_weight = Activation(activation='softmax')(dot)                        # shape = [BATCH_SIZE, LEN_S1, LEN_S2]\n",
    "s2_attention_weight = Activation(activation='softmax')(Permute(dims=[2, 1])(dot))  # shape = [BATCH_SIZE, LEN_S2, LEN_S1]\n",
    "s1_ = Dot(axes=-1)([s1_attention_weight, Permute(dims=[2, 1])(s2_encoded)])\n",
    "s2_ = Dot(axes=-1)([s2_attention_weight, Permute(dims=[2, 1])(s1_encoded)])\n",
    "ctx1 = ContextConcatenate([s1_encoded, s1_, SharpenContext([s1_encoded, s1_]), FilterContext([s1_encoded, s1_])])\n",
    "ctx2 = ContextConcatenate([s2_encoded, s2_, SharpenContext([s2_encoded, s2_]), FilterContext([s2_encoded, s2_])])\n",
    "# inference composition\n",
    "ctx1 = ContextEncoder2(ctx1)\n",
    "ctx2 = ContextEncoder2(ctx2)\n",
    "c1_avg = GlobalAveragePooling1D()(ctx1)\n",
    "c1_max = GlobalMaxPooling1D()(ctx1)\n",
    "c2_avg = GlobalAveragePooling1D()(ctx2)\n",
    "c2_max = GlobalMaxPooling1D()(ctx2)\n",
    "v = ContextConcatenate([c1_avg, c1_max, c2_avg, c2_max])\n",
    "result = Dense(1, activation='sigmoid', kernel_initializer=Ones(), bias_initializer=Ones())(v)\n",
    "\n",
    "# compile model\n",
    "mine = Model(inputs=[s1, s2], outputs=[result])\n",
    "mine.compile(optimizer='sgd', loss=binary_crossentropy)\n",
    "mine.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 别人编写的ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    100000      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 64)     34048       embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, None, None)   0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, None, None)   0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "softmax_2 (Softmax)             (None, None, None)   0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, None, 1 0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, None, 64)  0           bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, None, 1 0           softmax_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None, 1, 64)  0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, None, None, 6 0           lambda_1[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, None, None, 6 0           lambda_2[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None, 64)     0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, None, 64)     0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, None, 64)     0           bidirectional_3[0][0]            \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, None, 64)     0           bidirectional_3[0][0]            \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, None, 64)     0           bidirectional_3[1][0]            \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, None, 64)     0           bidirectional_3[1][0]            \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 256)    0           bidirectional_3[0][0]            \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 256)    0           bidirectional_3[1][0]            \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 32)     34944       concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 32)           0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 32)           0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 32)           0           bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 32)           0           bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           lambda_8[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 169,121\n",
      "Trainable params: 169,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Based on arXiv:1609.06038\n",
    "q1 = Input(batch_shape=[None, None])  # shape = [batch_size, seq_len]\n",
    "q2 = Input(batch_shape=[None, None])  # shape = [batch_size, seq_len]\n",
    "\n",
    "# Embedding\n",
    "embedding = Embedding(input_dim=LEN_VOC, output_dim=DIM_EMBEDDING, embeddings_initializer=Ones())\n",
    "\n",
    "q1_embed = embedding(q1)\n",
    "q2_embed = embedding(q2)\n",
    "\n",
    "# Encode\n",
    "bilstm = Bidirectional(LSTM(LSTM_UNIT1, return_sequences=True, recurrent_initializer=Ones(), kernel_initializer=Ones(), bias_initializer=Ones()))\n",
    "x1 = bilstm(q1_embed)\n",
    "x2 = bilstm(q2_embed)\n",
    "\n",
    "e = Dot(axes=2)([x1, x2])\n",
    "e1 = Softmax(axis=2)(e)\n",
    "e2 = Softmax(axis=1)(e)\n",
    "e1 = Lambda(K.expand_dims, arguments={'axis': 3})(e1)\n",
    "e2 = Lambda(K.expand_dims, arguments={'axis': 3})(e2)\n",
    "\n",
    "_x1 = Lambda(K.expand_dims, arguments={'axis': 1})(x2)\n",
    "_x1 = Multiply()([e1, _x1])\n",
    "_x1 = Lambda(K.sum, arguments={'axis': 2})(_x1)\n",
    "_x2 = Lambda(K.expand_dims, arguments={'axis': 2})(x1)\n",
    "_x2 = Multiply()([e2, _x2])\n",
    "_x2 = Lambda(K.sum, arguments={'axis': 1})(_x2)\n",
    "\n",
    "m1 = Concatenate()([x1, _x1, Subtract()([x1, _x1]), Multiply()([x1, _x1])])\n",
    "m2 = Concatenate()([x2, _x2, Subtract()([x2, _x2]), Multiply()([x2, _x2])])\n",
    "\n",
    "bilstm2 = Bidirectional(LSTM(LSTM_UNIT2, return_sequences=True, recurrent_initializer=Ones(), kernel_initializer=Ones(), bias_initializer=Ones()))\n",
    "y1 = bilstm2(m1)\n",
    "y2 = bilstm2(m2)\n",
    "\n",
    "mx1 = Lambda(K.max, arguments={'axis': 1})(y1)\n",
    "av1 = Lambda(K.mean, arguments={'axis': 1})(y1)\n",
    "mx2 = Lambda(K.max, arguments={'axis': 1})(y2)\n",
    "av2 = Lambda(K.mean, arguments={'axis': 1})(y2)\n",
    "\n",
    "y = Concatenate()([av1, mx1, av2, mx2])\n",
    "output = Dense(1, activation='sigmoid', kernel_initializer=Ones(), bias_initializer=Ones())(y)\n",
    "esim = Model(inputs=[q1, q2], outputs=[output])\n",
    "esim.compile(optimizer='sgd', loss=binary_crossentropy, metrics=['acc'])\n",
    "esim.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一些层的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1[:1]\n",
      "\n",
      " [[0.20315027 0.19419504 0.0391941  0.82134968 0.1305034  0.94363338\n",
      "  0.13618826 0.97851304 0.24774574 0.37293895 0.17771148 0.75703405\n",
      "  0.50921326 0.42383154 0.81686769 0.58488338 0.59101397 0.15340413\n",
      "  0.51231427 0.08793192 0.21079994 0.63293082 0.54531202 0.14813556\n",
      "  0.16403294 0.76736216 0.5181336  0.83074243 0.20470304 0.01973633\n",
      "  0.14425149 0.98327597 0.82249118 0.69700737 0.35186999 0.9811738\n",
      "  0.82977792 0.11704572 0.47706707 0.0146338  0.7075972  0.27989424\n",
      "  0.55196786 0.5637819  0.97258895 0.61683193 0.91119054 0.06611965\n",
      "  0.44703284 0.56086396]]\n",
      "x2[:1]\n",
      "\n",
      " [[0.78120823 0.72945504 0.7667443  0.58191879 0.39841785 0.43449338\n",
      "  0.63027284 0.50604932 0.15369607 0.88741095 0.78567249 0.41675698\n",
      "  0.0122022  0.58232796 0.13115551 0.2263666  0.2947192  0.71964085\n",
      "  0.24682478 0.96040925 0.09982975 0.14335222 0.76129882 0.32549239\n",
      "  0.48723311 0.85125139 0.20472467 0.5770125  0.41947864 0.85608947\n",
      "  0.94057238 0.03546743 0.2575981  0.50893252 0.39837772 0.05501654\n",
      "  0.98021617 0.85950884 0.33937463 0.16700002]]\n",
      "y_mine\n",
      "\n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "y_esim\n",
      "\n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.random.rand(BATCH_SIZE, LEN_S1)\n",
    "x2 = np.random.rand(BATCH_SIZE, LEN_S2)\n",
    "print('x1[:1]\\n\\n', x1[:1])\n",
    "print('x2[:1]\\n\\n', x2[:1])\n",
    "y_mine = mine.predict(x=[x1, x2])\n",
    "y_esim = esim.predict(x=[x1, x2])\n",
    "print('y_mine\\n\\n', y_mine)\n",
    "print('y_esim\\n\\n', y_esim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine_middle_layer [[[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]]\n",
      "esim_middle_layer [[[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]\n",
      "\n",
      " [[0.7615942 0.7615942 0.7615942 ... 1.        1.        1.       ]\n",
      "  [0.9640276 0.9640276 0.9640276 ... 1.        1.        1.       ]\n",
      "  [0.9950547 0.9950547 0.9950547 ... 1.        1.        1.       ]\n",
      "  ...\n",
      "  [1.        1.        1.        ... 0.9950547 0.9950547 0.9950547]\n",
      "  [1.        1.        1.        ... 0.9640276 0.9640276 0.9640276]\n",
      "  [1.        1.        1.        ... 0.7615942 0.7615942 0.7615942]]]\n"
     ]
    }
   ],
   "source": [
    "mine_middle_layer = Model(inputs=mine.inputs, outputs=[ctx1])\n",
    "esim_middle_layer = Model(inputs=esim.inputs, outputs=[av1])\n",
    "print('mine_middle_layer', mine_middle_layer.predict(x=[x1, x2]))\n",
    "print('esim_middle_layer', esim_middle_layer.predict(x=[x1, x2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结论\n",
    "\n",
    "- 从网络结构看，没错\n",
    "- 从参数数量上看是没错的\n",
    "- 从简单计算结果上看，也是没错的"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
